{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "045588ed-429c-4ec4-8cb3-e3f62417bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6667dc0-aeae-4fdf-a64d-fc935231a429",
   "metadata": {},
   "source": [
    "1. Find the least amount sale that was done for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65be5632-10bd-459e-944a-9450e7f37626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least amount sale for each item:\n",
      "           Item  Min_Sale_Amount\n",
      "0    Cell Phone           3375.0\n",
      "1          Desk            250.0\n",
      "2  Home Theater           2000.0\n",
      "3    Television           8386.0\n",
      "4   Video Games            936.0\n"
     ]
    }
   ],
   "source": [
    "sales_df = pd.read_excel('SalesData.xlsx')\n",
    "\n",
    "min_sales_by_item = sales_df.groupby('Item')['Sale_amt'].min().reset_index()\n",
    "min_sales_by_item.rename(columns={'Sale_amt': 'Min_Sale_Amount'}, inplace=True)\n",
    "\n",
    "print(\"Least amount sale for each item:\")\n",
    "print(min_sales_by_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20652001-fdcb-4869-b122-1c7e27f900f7",
   "metadata": {},
   "source": [
    "2. Compute the total sales for each year and region across all items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d771d819-0d0b-4a91-bc73-8503315ffbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sales for each year and region:\n",
      "   Year   Region  Sale_amt\n",
      "0  2018  Central  479825.0\n",
      "1  2018     East  293780.0\n",
      "2  2018     West  105424.0\n",
      "3  2019  Central  349944.5\n",
      "4  2019     East   27227.0\n",
      "5  2019     West   49475.0\n"
     ]
    }
   ],
   "source": [
    "# Extract year from OrderDate\n",
    "sales_df['Year'] = pd.to_datetime(sales_df['OrderDate']).dt.year\n",
    "\n",
    "total_sales_by_year_region = sales_df.groupby(['Year', 'Region'])['Sale_amt'].sum().reset_index()\n",
    "\n",
    "print(\"Total sales for each year and region:\")\n",
    "print(total_sales_by_year_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3fc2e2-2e0d-4e14-8c00-e910256eb3db",
   "metadata": {},
   "source": [
    "3. Create new column 'days_diff' with number of days difference between reference date passed and each order date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe852771-bddb-46de-a304-219905851627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with days_diff column:\n",
      "   OrderDate   Region  Manager   SalesMan          Item  Units  Unit_price  \\\n",
      "0 2018-01-06     East   Martha  Alexander    Television     95      1198.0   \n",
      "1 2018-01-23  Central  Hermann     Shelli  Home Theater     50       500.0   \n",
      "2 2018-02-09  Central  Hermann       Luis    Television     36      1198.0   \n",
      "3 2018-02-26  Central  Timothy      David    Cell Phone     27       225.0   \n",
      "4 2018-03-15     West  Timothy    Stephen    Television     56      1198.0   \n",
      "\n",
      "   Sale_amt  Year  days_diff  \n",
      "0  113810.0  2018        359  \n",
      "1   25000.0  2018        342  \n",
      "2   43128.0  2018        325  \n",
      "3    6075.0  2018        308  \n",
      "4   67088.0  2018        291  \n"
     ]
    }
   ],
   "source": [
    "# Convert OrderDate to datetime\n",
    "sales_df['OrderDate'] = pd.to_datetime(sales_df['OrderDate'])\n",
    "\n",
    "reference_date = pd.to_datetime('2018-12-31')\n",
    "\n",
    "# Calculate days difference\n",
    "sales_df['days_diff'] = (reference_date - sales_df['OrderDate']).dt.days\n",
    "\n",
    "print(\"DataFrame with days_diff column:\")\n",
    "print(sales_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff65dbec-dff7-45dd-8e57-b70a76c64377",
   "metadata": {},
   "source": [
    "4. Create a dataframe with two columns: 'manager', 'list_of_salesmen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e32cf0d8-804a-41f4-84d7-7f5273dd1fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with manager and list of salesmen:\n",
      "   manager            list_of_salesmen\n",
      "0  Douglas      [Michael, Karen, John]\n",
      "1  Hermann       [Shelli, Luis, Sigal]\n",
      "2   Martha  [Alexander, Steven, Diana]\n",
      "3  Timothy            [David, Stephen]\n"
     ]
    }
   ],
   "source": [
    "manager_salesmen = sales_df.groupby('Manager')['SalesMan'].unique().reset_index()\n",
    "manager_salesmen.columns = ['manager', 'list_of_salesmen']\n",
    "\n",
    "print(\"DataFrame with manager and list of salesmen:\")\n",
    "print(manager_salesmen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574caa3d-9e15-4b7c-8c8e-9ddd0d61e3f0",
   "metadata": {},
   "source": [
    "5. For all regions find number of salesman and total sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d030973-63e7-42be-9264-117b395b30ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region statistics:\n",
      "    Region  salesmen_count  total_sales\n",
      "0  Central               6     829769.5\n",
      "1     East               3     321007.0\n",
      "2     West               2     154899.0\n"
     ]
    }
   ],
   "source": [
    "region_stats = sales_df.groupby('Region').agg(\n",
    "    salesmen_count=('SalesMan', 'nunique'),\n",
    "    total_sales=('Sale_amt', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "print(\"Region statistics:\")\n",
    "print(region_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0466b679-c51d-47a5-a0ed-1428cda1feee",
   "metadata": {},
   "source": [
    "6. Create a dataframe with total sales as percentage for each manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e8eebfa-74ea-447b-8704-610e71eaa5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manager sales percentage:\n",
      "   manager  percent_sales\n",
      "0  Douglas      18.308990\n",
      "1  Hermann      27.963188\n",
      "2   Martha      36.187629\n",
      "3  Timothy      17.540193\n"
     ]
    }
   ],
   "source": [
    "# Calculate total sales for each manager\n",
    "manager_sales = sales_df.groupby('Manager')['Sale_amt'].sum()\n",
    "\n",
    "# Calculate overall total sales\n",
    "total_sales = sales_df['Sale_amt'].sum()\n",
    "\n",
    "# Calculate percentage\n",
    "manager_percent = (manager_sales / total_sales * 100).reset_index()\n",
    "manager_percent.columns = ['manager', 'percent_sales']\n",
    "\n",
    "print(\"Manager sales percentage:\")\n",
    "print(manager_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e685c4e-f122-4057-a344-4e3618891b23",
   "metadata": {},
   "source": [
    "7. Get the imdb rating for fifth movie of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "541306a3-a10e-4cc6-9079-e8c90dc41771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB rating for fifth movie: 8.7\n"
     ]
    }
   ],
   "source": [
    "# Use on_bad_lines='skip'\n",
    "imdb_df = pd.read_csv('imdb.csv', on_bad_lines='skip')\n",
    "\n",
    "# Get IMDB rating for fifth movie (assuming 0-indexed)\n",
    "fifth_movie_rating = imdb_df.iloc[4]['imdbRating']\n",
    "print(f\"IMDB rating for fifth movie: {fifth_movie_rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c81392-4ead-4721-8081-80e5566617f7",
   "metadata": {},
   "source": [
    "8. Return titles of movies with shortest and longest run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "119cedd1-2a61-4c6a-a63f-4c9197f54c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest movie: Traffic Crossing Leeds Bridge (1888) (Duration: 2.0 seconds)\n",
      "Longest movie: Baseball The National Pastime (TV Episode 1994) (Duration: 68400.0 seconds)\n"
     ]
    }
   ],
   "source": [
    "shortest_movie = imdb_df.loc[imdb_df['duration'].idxmin()]\n",
    "longest_movie = imdb_df.loc[imdb_df['duration'].idxmax()]\n",
    "\n",
    "print(f\"Shortest movie: {shortest_movie['title']} (Duration: {shortest_movie['duration']} seconds)\")\n",
    "print(f\"Longest movie: {longest_movie['title']} (Duration: {longest_movie['duration']} seconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52856da8-529b-4878-8f6e-26e56358359e",
   "metadata": {},
   "source": [
    "9. Sort by release date (earliest) and IMDB rating (highest to lowest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69ed891b-ea2e-470c-843e-180157189d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted by release date and rating:\n",
      "                                        title    year  imdbRating\n",
      "13605            Roundhay Garden Scene (1888)  1888.0         7.8\n",
      "13282    Traffic Crossing Leeds Bridge (1888)  1888.0         7.2\n",
      "6705                  Blacksmith Scene (1893)  1893.0         6.3\n",
      "12316  Dickson Experimental Sound Film (1894)  1894.0         6.8\n",
      "6706            The Kiss in the Tunnel (1899)  1899.0         5.9\n"
     ]
    }
   ],
   "source": [
    "sorted_imdb = imdb_df.sort_values(by=['year', 'imdbRating'], ascending=[True, False])\n",
    "\n",
    "print(\"Sorted by release date and rating:\")\n",
    "print(sorted_imdb[['title', 'year', 'imdbRating']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795795f-7975-4d5d-8807-e14915683f23",
   "metadata": {},
   "source": [
    "10. Subset with movies having duration between 30 and 180 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ab352ad-36c7-4180-9257-8d902ecf6206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies with duration between 30 and 180 minutes: 11952\n",
      "                              title  duration_minutes\n",
      "0  Der Vagabund und das Kind (1921)              54.0\n",
      "1                 Goldrausch (1925)              95.0\n",
      "2                 Metropolis (1927)             153.0\n",
      "3                Der General (1926)             107.0\n",
      "4      Lichter der GroÃŸstadt (1931)              87.0\n"
     ]
    }
   ],
   "source": [
    "# Convert duration from seconds to minutes\n",
    "imdb_df['duration_minutes'] = imdb_df['duration'] / 60\n",
    "\n",
    "# Filter movies with duration between 30 and 180 minutes\n",
    "filtered_movies = imdb_df[(imdb_df['duration_minutes'] >= 30) & (imdb_df['duration_minutes'] <= 180)]\n",
    "\n",
    "print(f\"Number of movies with duration between 30 and 180 minutes: {len(filtered_movies)}\")\n",
    "print(filtered_movies[['title', 'duration_minutes']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e01c2fa-02da-4923-a413-6308b219a6f4",
   "metadata": {},
   "source": [
    "11. Count the duplicate rows of diamonds DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a063f8d7-4461-431e-a7d1-4fbbcaff5d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 149\n"
     ]
    }
   ],
   "source": [
    "diamonds_df = pd.read_csv('diamonds.csv')\n",
    "\n",
    "duplicate_count = diamonds_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11910f51-39f0-4c58-a517-c3bbf5faef2a",
   "metadata": {},
   "source": [
    "12. Drop rows in case of missing values in carat and cut columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cdb25f4-589a-492f-b89b-cfec9976dcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original row count: 53943\n",
      "Row count after dropping missing values: 53941\n"
     ]
    }
   ],
   "source": [
    "cleaned_diamonds = diamonds_df.dropna(subset=['carat', 'cut'])\n",
    "\n",
    "print(f\"Original row count: {len(diamonds_df)}\")\n",
    "print(f\"Row count after dropping missing values: {len(cleaned_diamonds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ba09b6-bf41-4331-a96f-ae64abb34e43",
   "metadata": {},
   "source": [
    "13. Subset the dataframe with only numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4199e8a0-4b76-443f-b914-e0e02a88d48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with only numeric columns:\n",
      "   depth  table  price     x     y     z\n",
      "0   61.5   55.0  326.0  3.95  3.98  2.43\n",
      "1   59.8   61.0  326.0  3.89  3.84  2.31\n",
      "2   56.9   65.0  327.0  4.05  4.07  2.31\n",
      "3   62.4   58.0  334.0  4.20  4.23  2.63\n",
      "4   63.3   58.0  335.0  4.34  4.35  2.75\n",
      "Numeric columns: ['depth', 'table', 'price', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "numeric_diamonds = diamonds_df.select_dtypes(include=[np.number])\n",
    "\n",
    "print(\"DataFrame with only numeric columns:\")\n",
    "print(numeric_diamonds.head())\n",
    "print(f\"Numeric columns: {numeric_diamonds.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b05fa9d-cc94-4dc3-a27c-000a6adcaf97",
   "metadata": {},
   "source": [
    "14. Compute volume as (xyz) when depth is greater than 60, otherwise default to 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cf87559-d5c4-4b65-a372-762afee8ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with volume column:\n",
      "  carat  depth     x     y     z    volume\n",
      "0  0.23   61.5  3.95  3.98  2.43  38.20203\n",
      "1  0.21   59.8  3.89  3.84  2.31   8.00000\n",
      "2  0.23   56.9  4.05  4.07  2.31   8.00000\n",
      "3  0.29   62.4  4.20  4.23  2.63  46.72458\n",
      "4  0.31   63.3  4.34  4.35  2.75  51.91725\n"
     ]
    }
   ],
   "source": [
    "diamonds_df['volume'] = np.where(\n",
    "    diamonds_df['depth'] > 60,\n",
    "    diamonds_df['x'] * diamonds_df['y'] * diamonds_df['z'],\n",
    "    8\n",
    ")\n",
    "\n",
    "print(\"DataFrame with volume column:\")\n",
    "print(diamonds_df[['carat', 'depth', 'x', 'y', 'z', 'volume']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d55ce90-f130-4ad7-a3a4-fb3d5be1b4c7",
   "metadata": {},
   "source": [
    "15. Impute missing price values with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40c10a87-3e46-40f6-abb9-e54ee03ec3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean price used for imputation: 3932.8585253712527\n",
      "DataFrame after imputing missing prices:\n",
      "  carat      cut  price\n",
      "0  0.23    Ideal  326.0\n",
      "1  0.21  Premium  326.0\n",
      "2  0.23     Good  327.0\n",
      "3  0.29  Premium  334.0\n",
      "4  0.31     Good  335.0\n"
     ]
    }
   ],
   "source": [
    "mean_price = diamonds_df['price'].mean()\n",
    "\n",
    "# Fill missing price values with mean\n",
    "diamonds_df['price'] = diamonds_df['price'].fillna(mean_price)\n",
    "\n",
    "print(f\"Mean price used for imputation: {mean_price}\")\n",
    "print(\"DataFrame after imputing missing prices:\")\n",
    "print(diamonds_df[['carat', 'cut', 'price']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
